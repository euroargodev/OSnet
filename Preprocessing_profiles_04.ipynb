{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home1/datahome/mlejeune'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime as dt\n",
    "import glob\n",
    "import netCDF4 as nc\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import xarray as xr\n",
    "import gsw\n",
    "from gsw import *\n",
    "import cmocean\n",
    "from datetime import datetime\n",
    "\n",
    "import cartopy\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "from cartopy.mpl.ticker import LongitudeFormatter, LatitudeFormatter\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "cartopy.config[\"data_dir\"] = './cartopy_shapefiles'\n",
    "\n",
    "import yaml\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File version:  0.1\n"
     ]
    }
   ],
   "source": [
    "with open(r'/home1/datahome/mlejeune/configuration.yaml') as file:\n",
    "    configuration = yaml.load(file, Loader=yaml.FullLoader)\n",
    "\n",
    "    print(\"File version: \", configuration[\"version\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930128_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930205_PR_CT_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19931019_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930906_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930927_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930901_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930525_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930611_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19931205_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930818_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930430_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930613_PR_UD_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19931101_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930606_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19931130_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930222_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930729_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930614_PR_UD_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930713_PR_UD_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930509_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930425_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930805_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930823_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930829_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930310_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930617_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930519_PR_IC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930530_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930126_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930323_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930527_PR_OC_Nordic_Sea.nc\n",
      "delete file:  /home1/datahome/mlejeune/cora_Nordic_Sea/test/CO_DMQCGL01_19930719_PR_IC_Nordic_Sea.nc\n"
     ]
    }
   ],
   "source": [
    "# Clean OutPut\n",
    "Delete = False;\n",
    "haveToCreate = False;\n",
    "\n",
    "if(Delete):\n",
    "    haveToCreate = True;\n",
    "    if len(os.listdir(configuration['CORA_OUTPUT'])) != 0:\n",
    "    \n",
    "         arr = os.listdir(configuration['CORA_OUTPUT'])\n",
    "         for x in arr:\n",
    "             os.remove((configuration['CORA_OUTPUT'] + x))\n",
    "             print(\"delete file: \", (configuration['CORA_OUTPUT'] + x))\n",
    "             \n",
    "    else:    \n",
    "        print(\"Directory is empty\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted a total of 7156 TS profiles in the Nordic sea Region, for the year 2019.\n",
      "CPU times: user 42 s, sys: 8.6 s, total: 50.6 s\n",
      "Wall time: 4min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "haveToCreate = True\n",
    "if(haveToCreate):\n",
    "    cora_rep = configuration['CORA_DATA_REP']\n",
    "    data_rep = configuration['CORA_OUTPUT']\n",
    "\n",
    "    for yy in range(2019,2020):\n",
    "        listfile = set(glob.glob(cora_rep + str(yy) + '/CO_*.nc')) - set(glob.glob(cora_rep + str(yy) + '/*MO.nc')) - set(glob.glob(cora_rep + str(yy) + '/*TE.nc')) - set(glob.glob(cora_rep + str(yy) + '/*DB.nc'))\n",
    "        count = list()\n",
    "        for myfile in listfile:\n",
    "            filename = os.path.basename(myfile)\n",
    "            ds = nc.Dataset(myfile, 'r')  # r+\n",
    "            dm = ds.variables['DATA_MODE'][:]\n",
    "            dcref = ds.variables['DC_REFERENCE'][:,:]\n",
    "            lon   = ds.variables['LONGITUDE'][:]\n",
    "            lat   = ds.variables['LATITUDE'][:]\n",
    "            juld  = ds.variables['JULD'][:]\n",
    "            platform_number = ds.variables['PLATFORM_NUMBER'][:]\n",
    "            ind     = list()\n",
    "            mydcref = list()\n",
    "            mypfnum = list()\n",
    "            for ii in range(0,len(dm)):\n",
    "                suffix  =''\n",
    "                #REGION\n",
    "                if lon[ii]<=configuration['longitude2_oceans'] and lon[ii]>=configuration['longitude1_oceans'] and lat[ii]<=configuration['latitude1_oceans'] and lat[ii]>=configuration['latitude2_oceans']:\n",
    "                        \n",
    "                    #ADJUSTED IF IT EXIST\n",
    "                    if dm[ii] == b'A' or dm[ii] == b'D':\n",
    "                        suffix = '_ADJUSTED'\n",
    "                    #TEMP AND PSAL AND PRES\n",
    "                    if 'TEMP' in ds.variables.keys() and 'PSAL' in ds.variables.keys() and 'PRES' in ds.variables.keys():\n",
    "                        ind.append(ii)\n",
    "                        dc = b''.join(dcref[ii,dcref[ii,:].mask== False])\n",
    "                        dc = dc.decode('utf-8')\n",
    "                        mydcref.append(dc)\n",
    "                        pf = b''.join(platform_number[ii,platform_number[ii,:].mask== False])\n",
    "                        mypfnum.append(pf)\n",
    "                        \n",
    "            if len(ind)>0:\n",
    "                count.append(len(ind))\n",
    "                #RETRIEVE QC FOR ind AND CREATE MASK FROM IT\n",
    "                mask_TEMP = np.isin(ds.variables['TEMP' + suffix  + '_QC'][ind,:].data, b'1')\n",
    "                mask_PSAL = np.isin(ds.variables['PSAL' + suffix  + '_QC'][ind,:].data, b'1')\n",
    "                mask_PRES = np.isin(ds.variables['PRES' + suffix  + '_QC'][ind,:].data, b'1')\n",
    "                #MAKE A SINGLE MASK FROM THE COMBINED THREE OTHERS\n",
    "                mask = mask_TEMP & mask_PSAL & mask_PRES\n",
    "                #EXPORT IN DATASET XARRAY\n",
    "                dsxr = xr.Dataset(\n",
    "                data_vars=dict(\n",
    "                    TEMP = ([\"N_PROF\",\"N_PRES\"], ma.masked_array(ds.variables['TEMP' + suffix ][ind,:], mask=~mask)),\n",
    "                    PSAL = ([\"N_PROF\",\"N_PRES\"], ma.masked_array(ds.variables['PSAL' + suffix ][ind,:], mask=~mask)),\n",
    "                    PRES = ([\"N_PROF\",\"N_PRES\"], ma.masked_array(ds.variables['PRES' + suffix ][ind,:], mask=~mask)),\n",
    "                    DC_REFERENCE    = ([\"N_PROF\"], mydcref),\n",
    "                    PLATFORM_NUMBER = ([\"N_PROF\"], mypfnum)\n",
    "                ),\n",
    "                coords=dict(\n",
    "                    LON  = ([\"N_PROF\"], lon[ind]),\n",
    "                    LAT  = ([\"N_PROF\"], lat[ind]),\n",
    "                    JULD = ([\"N_PROF\"],juld[ind])\n",
    "                ),\n",
    "                attrs=dict(description=\"CORA subsampled : Selection of profiles with (1) TEMP, PSAL and PRES present, (2) adjusted data if adjusted exist \"),\n",
    "                )\n",
    "                dsxr.JULD.attrs[\"units\"] = \"days since 1950-01-01\"\n",
    "                dsxr['DC_REFERENCE'] = dsxr['DC_REFERENCE'].astype('|S8')\n",
    "                dsxr.to_netcdf(data_rep + myfile[50:76] + \"_Nordic_Sea.nc\")\n",
    "            ds.close()\n",
    "        print('Extracted a total of ' + str(sum(count)) + ' TS profiles in the Nordic sea Region, for the year ' + str(yy) + '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.719269535463235% done\n",
      "6562 profiles processed\n",
      "7.43853907092647% done\n",
      "14219 profiles processed\n",
      "11.157808606389704% done\n",
      "24668 profiles processed\n",
      "14.87707814185294% done\n",
      "35105 profiles processed\n",
      "18.596347677316174% done\n",
      "44190 profiles processed\n",
      "22.315617212779408% done\n",
      "51558 profiles processed\n",
      "26.03488674824265% done\n",
      "57823 profiles processed\n",
      "29.75415628370588% done\n",
      "63282 profiles processed\n",
      "33.473425819169115% done\n",
      "68121 profiles processed\n",
      "37.19269535463235% done\n",
      "73856 profiles processed\n",
      "40.91196489009559% done\n",
      "79790 profiles processed\n",
      "44.631234425558816% done\n",
      "84986 profiles processed\n",
      "48.350503961022056% done\n",
      "90749 profiles processed\n",
      "52.0697734964853% done\n",
      "98078 profiles processed\n",
      "55.78904303194852% done\n",
      "104106 profiles processed\n",
      "59.50831256741176% done\n",
      "113574 profiles processed\n",
      "63.22758210287499% done\n",
      "123357 profiles processed\n",
      "66.94685163833823% done\n",
      "135387 profiles processed\n",
      "70.66612117380147% done\n",
      "144298 profiles processed\n",
      "74.3853907092647% done\n",
      "153007 profiles processed\n",
      "78.10466024472792% done\n",
      "160260 profiles processed\n",
      "81.82392978019118% done\n",
      "167419 profiles processed\n",
      "85.5431993156544% done\n",
      "173451 profiles processed\n",
      "89.26246885111763% done\n",
      "179580 profiles processed\n",
      "92.98173838658087% done\n",
      "185814 profiles processed\n",
      "96.70100792204411% done\n",
      "192337 profiles processed\n",
      "finished, concatenation starting\n",
      "CPU times: user 18min 52s, sys: 19.2 s, total: 19min 11s\n",
      "Wall time: 1h 6min 54s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pi = configuration['PI']\n",
    "\n",
    "listfile = glob.glob(configuration['CORA_OUTPUT'] + '*.nc');\n",
    "data_rep = configuration['CORA_OUTPUT'];\n",
    "\n",
    "total_files = len(listfile)\n",
    "datasets = []\n",
    "nb_prof = 0\n",
    "count = 0\n",
    "\n",
    "for myfile in listfile:\n",
    "    ds = xr.open_dataset(myfile)\n",
    "    ds = ds.dropna('N_PROF', how = \"all\", subset=['TEMP', 'PSAL'])\n",
    "    N = len(ds.N_PROF)\n",
    "    #Exclude empty files\n",
    "    if N>0:\n",
    "        TEMPi = np.empty((N,len(pi)))\n",
    "        TEMPi[:] = np.nan\n",
    "        PSALi = np.empty((N,len(pi)))\n",
    "        PSALi[:] = np.nan\n",
    "        TEMPs = np.empty((N,len(pi)))\n",
    "        TEMPs[:] = np.nan\n",
    "        PSALs = np.empty((N,len(pi)))\n",
    "        PSALs[:] = np.nan\n",
    "        for n in range(0,N):\n",
    "            TEMPi[n,:] = np.interp(pi, ds.PRES[n,:], ds.TEMP[n,:],right=np.nan)\n",
    "            PSALi[n,:] = np.interp(pi, ds.PRES[n,:], ds.PSAL[n,:],right=np.nan)\n",
    "            TEMPs[n,:] = np.interp(pi, ds.PRES[n,:], ds.TEMP[n,:],left=np.nan,right=np.nan)\n",
    "            PSALs[n,:] = np.interp(pi, ds.PRES[n,:], ds.PSAL[n,:],left=np.nan,right=np.nan)\n",
    "            #EXPORT INTERPOLATED PROFILES\n",
    "        dsi = xr.Dataset(\n",
    "            data_vars=dict(\n",
    "                TEMP_SURF = ([\"N_PROF\",\"PRES_INTERPOLATED\"], TEMPs),\n",
    "                PSAL_SURF = ([\"N_PROF\",\"PRES_INTERPOLATED\"], PSALs),\n",
    "                TEMP_INTERP = ([\"N_PROF\",\"PRES_INTERPOLATED\"], TEMPi),\n",
    "                PSAL_INTERP = ([\"N_PROF\",\"PRES_INTERPOLATED\"], PSALi),\n",
    "                DC_REFERENCE    = ([\"N_PROF\"], ds.DC_REFERENCE.data),\n",
    "                PLATFORM_NUMBER = ([\"N_PROF\"], ds.PLATFORM_NUMBER.data)),\n",
    "            coords=dict(\n",
    "                LON  = ([\"N_PROF\"], ds.LON.data),\n",
    "                LAT  = ([\"N_PROF\"], ds.LAT.data),\n",
    "                PRES_INTERPOLATED  = ([\"PRES_INTERPOLATED\"], pi),\n",
    "                JULD = ([\"N_PROF\"],ds.JULD.data)))\n",
    "        datasets.append(dsi)\n",
    "        nb_prof = nb_prof + len(dsi.N_PROF)\n",
    "    count = count+1\n",
    "    if count % 1000 == 0:\n",
    "        print(f\"{(count/total_files)*100}% done\")\n",
    "        print(f\"{nb_prof} profiles processed\")\n",
    "        \n",
    "print('finished, concatenation starting')\n",
    "ds_interp = xr.concat(datasets, dim='N_PROF')\n",
    "ds_interp.to_netcdf(data_rep + \"ds_interp.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_name = \"temporaire.nc\"\n",
    "data_rep = configuration['CORA_OUTPUT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Delete = True;\n",
    "if(Delete):\n",
    "    os.remove(data_rep + configuration['CORA_FILE_NAME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of nan left: 0\n"
     ]
    }
   ],
   "source": [
    "ds = xr.open_dataset(data_rep +\"ds_interp.nc\")\n",
    "ds = ds.dropna('N_PROF', how = \"any\", subset=['TEMP_INTERP', 'PSAL_INTERP'])\n",
    "x = np.array(ds.TEMP_INTERP)\n",
    "\n",
    "print(f\"number of nan left: {np.count_nonzero(np.isnan(x))}\")\n",
    "\n",
    "#Select the period \n",
    "ds = ds.where(ds.JULD.dt.year<=configuration['YEARS_2']\n",
    "              ,drop = True)\n",
    "ds = ds.where(ds.JULD.dt.year>=configuration['YEARS_1'],drop = True)\n",
    "\n",
    "ds_clean = ds.where(np.isnan(ds['TEMP_SURF'].isel(PRES_INTERPOLATED=14))==False, drop=True)\n",
    "ds_clean = ds_clean.rename({'LAT': 'LATITUDE', 'LON':'LONGITUDE', 'JULD':'TIME'})\n",
    "ds_clean.to_netcdf(data_rep + temp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16 ms, sys: 8 ms, total: 24 ms\n",
      "Wall time: 107 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#Load Data\n",
    "data_rep = configuration['CORA_OUTPUT']\n",
    "ds = xr.open_dataset(data_rep + temp_name)\n",
    "\n",
    "lats = ds.LATITUDE\n",
    "lons = ds.LONGITUDE\n",
    "dates = ds.TIME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 80 ms, sys: 28 ms, total: 108 ms\n",
      "Wall time: 4.79 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#BATHYMETRY\n",
    "ds_bat = xr.open_dataset(configuration['BATHYMETRIE_output_path'] + configuration['BATHYMETRIE_FILE_NAME'])\n",
    "res_lin = ds_bat.interp(LATITUDE=lats,LONGITUDE=lons,method = 'linear')['bathymetry'].values\n",
    "ds = ds.assign(variables={\"bathy\": (('N_PROF'), res_lin)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 212 ms, sys: 932 ms, total: 1.14 s\n",
      "Wall time: 1.35 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "#MDT\n",
    "ds_mdt = xr.open_dataset(configuration['MDT_DATA_path'])\n",
    "ds_mdt = ds_mdt.assign_coords(lon180=(((ds_mdt.longitude + 180) % 360) - 180))  \n",
    "ds_mdt['longitude'] = ds_mdt.lon180\n",
    "res = ds_mdt.interp(latitude=lats,longitude=lons,method = 'nearest')['mdt'].values[0]\n",
    "ds = ds.assign(variables={\"MDT\": (('N_PROF'), res)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.8 s, sys: 11.1 s, total: 23.9 s\n",
      "Wall time: 4min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#SST\n",
    "path = configuration['SST_output_path']\n",
    "ds_sst = xr.open_mfdataset(path + '*.nc')\n",
    "spatial_domain = {\"lon\":[configuration['longitude1'], configuration['longitude2']],\n",
    "                 \"lat\": [configuration['latitude2'], configuration['latitude1']]}\n",
    "\n",
    "ds_sst = ds_sst.sel(lon=slice(spatial_domain['lon'][0], spatial_domain['lon'][1]),\n",
    "                    lat=slice(spatial_domain['lat'][0], spatial_domain['lat'][1]))\n",
    "res = ds_sst.sel(dict(lat=lats, lon=lons, time=dates), method='nearest')['analysed_sst'].values-273.15\n",
    "\n",
    "ds = ds.assign(variables={\"SST\": (('N_PROF'), res)})\n",
    "res = ds_sst.sel(dict(lat=lats, lon=lons, time=dates), method='nearest')['analysis_uncertainty'].values\n",
    "ds = ds.assign(variables={\"SST_uncertainty\": (('N_PROF'), res)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<xarray.Dataset>\n",
      "Dimensions:            (N_PROF: 51433, PRES_INTERPOLATED: 51)\n",
      "Coordinates:\n",
      "    LONGITUDE          (N_PROF) float64 -20.0 -20.0 -20.0 ... -0.128 2.444\n",
      "    LATITUDE           (N_PROF) float64 60.02 60.5 60.02 ... 67.79 72.2 69.6\n",
      "  * PRES_INTERPOLATED  (PRES_INTERPOLATED) int64 0 1 2 3 4 ... 773 857 950 1000\n",
      "    TIME               (N_PROF) datetime64[ns] 1993-08-27 ... 2020-06-25T17:5...\n",
      "Dimensions without coordinates: N_PROF\n",
      "Data variables:\n",
      "    TEMP_SURF          (N_PROF, PRES_INTERPOLATED) float64 ...\n",
      "    PSAL_SURF          (N_PROF, PRES_INTERPOLATED) float64 ...\n",
      "    TEMP_INTERP        (N_PROF, PRES_INTERPOLATED) float64 ...\n",
      "    PSAL_INTERP        (N_PROF, PRES_INTERPOLATED) float64 ...\n",
      "    DC_REFERENCE       (N_PROF) |S8 ...\n",
      "    PLATFORM_NUMBER    (N_PROF) |S8 ...\n",
      "    bathy              (N_PROF) float64 -2.725e+03 -2.535e+03 ... -3.252e+03\n",
      "    MDT                (N_PROF) float64 -0.2061 -0.2403 ... -0.4401 -0.2753\n",
      "    SST                (N_PROF) float32 0.52 0.52 0.52 0.52 ... 4.4 5.67 9.37\n",
      "    SST_uncertainty    (N_PROF) float32 0.77 0.77 0.77 0.77 ... 0.62 0.53 0.37\n"
     ]
    }
   ],
   "source": [
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.7 s, sys: 1.97 s, total: 19.7 s\n",
      "Wall time: 1min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#SLA\n",
    "path_SLA = configuration['SLA_path']\n",
    "ds_sla = xr.open_mfdataset(path_SLA + '*.nc')\n",
    "spatial_domain = {\"lon\":[configuration['longitude1'], configuration['longitude2']],\n",
    "                 \"lat\": [configuration['latitude2'], configuration['latitude1']]}\n",
    "\n",
    "ds_sla = ds_sla.sortby('longitude')\n",
    "\n",
    "ds_sla = ds_sla.sel(longitude=slice(spatial_domain['lon'][0], spatial_domain['lon'][1]),\n",
    "                    latitude=slice(spatial_domain['lat'][0], spatial_domain['lat'][1]))\n",
    "\n",
    "res = ds_sla.sel(dict(latitude=lats, longitude=lons, time=dates), method='nearest')\n",
    "ds = ds.assign(variables={\"SLA\": (('N_PROF'), res['sla'].values)}) \n",
    "ds = ds.assign(variables={\"UGOS\": (('N_PROF'), res['ugos'].values)}) \n",
    "ds = ds.assign(variables={\"VGOS\": (('N_PROF'), res['vgos'].values)}) \n",
    "ds = ds.assign(variables={\"UGOSA\": (('N_PROF'), res['ugosa'].values)}) \n",
    "ds = ds.assign(variables={\"VGOSA\": (('N_PROF'), res['vgosa'].values)}) \n",
    "ds = ds.assign(variables={\"SLA_err\": (('N_PROF'), res['err'].values)}) \n",
    "\n",
    "ds = ds.dropna('N_PROF', how = \"all\", subset=['SLA']) #Remove all NaN in SLA\n",
    "ds = ds.dropna('N_PROF', how = \"all\", subset=['UGOS']) #Remove all NaN in SLA\n",
    "\n",
    "ds.to_netcdf(data_rep + \"temp_last.nc\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no prof to fix\n",
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 380 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "    \n",
    "#Find NaN if any\n",
    "UGOS = np.array(ds.UGOS)\n",
    "indna = np.argwhere(np.isnan(UGOS))[:,0]\n",
    "\n",
    "if len(indna)>0:\n",
    "    print(f\"{len(indna)} prof to fix\")\n",
    "    \n",
    "    print(indna) #print all N_PROF id of NaN\n",
    "    \n",
    "    fig = plt.figure(figsize=(12, 12))\n",
    "    ax = plt.axes(projection=ccrs.PlateCarree())\n",
    "\n",
    "    plt.title('Nan in SLA')\n",
    "\n",
    "    ax.set_extent([17, -30, 50, 85], ccrs.PlateCarree())\n",
    "    ax.coastlines(resolution='110m')\n",
    "\n",
    "    histo_data = [];\n",
    "\n",
    "    # add every Nan to map\n",
    "    for i in range(len(indna)):\n",
    "        lon_temp = np.array(ds.UGOS[indna[i]].LONGITUDE)\n",
    "        lat_temp = np.array(ds.UGOS[indna[i]].LATITUDE)\n",
    "\n",
    "        str = np.array2string(np.array(ds.UGOS[indna[i]].TIME))\n",
    "        year = str[1:5]\n",
    "\n",
    "        histo_data.append(year)\n",
    "\n",
    "        plt.plot(lon_temp, lat_temp,  markersize=5, marker='o', color='red') #longitude * latide\n",
    "\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "\n",
    "    plt.hist(histo_data)\n",
    "    plt.title('NaN Evolution', fontsize=10)\n",
    "    plt.show()\n",
    "    \n",
    "else:\n",
    "    print(\"no prof to fix\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "deleting temporary file ..\n",
      "removed\n",
      "Starting generation finalDataset File\n"
     ]
    }
   ],
   "source": [
    "#Load Data\n",
    "ds.to_netcdf(data_rep + \"temp_last.nc\")\n",
    "\n",
    "# reformating and renaming\n",
    "s = ds.rename({\"TEMP_INTERP\": \"TEMP\", \"PSAL_INTERP\": \"PSAL\"}) # coder verification si le nom à déjà changer !\n",
    "\n",
    "ds = s;\n",
    "\n",
    "SA = gsw.SA_from_SP(ds['PSAL'], ds['PRES_INTERPOLATED'], ds['LONGITUDE'], ds['LATITUDE'])\n",
    "CT = gsw.CT_from_t(SA, ds['TEMP'], ds['PRES_INTERPOLATED'])\n",
    "SIG = gsw.sigma0(SA, CT)\n",
    "ds = ds.assign(variables={\"SA\": (('N_PROF', 'PRES_INTERPOLATED'), SA.data)})\n",
    "ds = ds.assign(variables={\"CT\": (('N_PROF', 'PRES_INTERPOLATED'), CT.data)})\n",
    "ds = ds.assign(variables={\"SIG\": (('N_PROF', 'PRES_INTERPOLATED'), SIG.data)})\n",
    "\n",
    "sig_diff = ds.SIG - ds.SIG.sel(PRES_INTERPOLATED = 10)-0.03\n",
    "MLD_obs = ds['PRES_INTERPOLATED'].where(sig_diff>0).min(dim='PRES_INTERPOLATED')\n",
    "ds = ds.assign(MLD = MLD_obs)\n",
    "\n",
    "print('deleting temporary file ..')\n",
    "\n",
    "os.remove(data_rep + \"temp_last.nc\")\n",
    "os.remove(data_rep + temp_name)\n",
    "\n",
    "print(\"removed\")\n",
    "print(\"Starting generation finalDataset File\")\n",
    "ds.to_netcdf(data_rep + configuration['OUTPUT_FILE_NAME'])\n",
    "print(\"done !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:OsNetex]",
   "language": "python",
   "name": "conda-env-OsNetex-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
